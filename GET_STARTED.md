# üéâ AI Agents Created Successfully!

## What You Now Have

**TWO** complete AI agent systems that provide natural language access to your 14 MCP tools:

1. **ü§ñ Claude Agent** - Cloud-based, premium quality (paid)
2. **ü¶ô Ollama Agent** - Local, open-source LLMs (FREE!)

Choose based on your needs: quality + speed (Claude) or privacy + cost (Ollama).

## üì¶ Created Files (13)

### Claude Agent (Cloud-based)
- `src/agent/ai-agent.ts` - Claude API agent class
- `src/agent/agent-api.ts` - REST API endpoints
- `src/agent/cli.ts` - Interactive CLI
- `src/agent/example-usage.ts` - Code examples

### Ollama Agent (Local/FREE)
- `src/agent/ollama-agent.ts` - Ollama agent class
- `src/agent/ollama-agent-api.ts` - REST API endpoints
- `src/agent/ollama-cli.ts` - Interactive CLI

### Documentation  
- `src/agent/README.md` - Comprehensive agent documentation
- `docs/AI_AGENT_SETUP.md` - Claude setup guide
- `docs/AI_AGENT_QUICK_REF.md` - Quick reference card
- `docs/OLLAMA_AGENT_SETUP.md` - Ollama setup guide (comprehensive)
- `docs/OLLAMA_QUICK_START.md` - Ollama quick start (5 min)
- `docs/AGENT_COMPARISON.md` - Claude vs Ollama comparison
- `AI_AGENT_IMPLEMENTATION.md` - Implementation summary
- `GET_STARTED.md` - This file

### Dependencies Installed
- `@anthropic-ai/sdk` - Claude API client
- `ollama` - Ollama Node.js client
- `chalk@4` - CLI colors

## ‚ú® Features (Both Agents)

‚úÖ **Natural Language Queries** - "What are the active sprints?" instead of API calls  
‚úÖ **Multi-Tool Orchestration** - Agent automatically chains multiple tools  
‚úÖ **Conversation Memory** - Maintains context across multiple questions  
‚úÖ **Streaming Responses** - Real-time output for better UX  
‚úÖ **RESTful API** - Easy integration with web/mobile apps  
‚úÖ **CLI Tool** - Interactive terminal interface  
‚úÖ **14 MCP Tools** - Full access to Jira, GitHub, and reporting  

### Claude Agent Specific
‚úÖ **Premium Quality** - GPT-4 class reasoning  
‚úÖ **Fast Responses** - Cloud-based, optimized inference  
‚úÖ **High Reliability** - 99.9% uptime  
‚úÖ **Cost** - ~$0.01-0.05 per query  

### Ollama Agent Specific
‚úÖ **100% FREE** - Zero API costs, unlimited queries  
‚úÖ **Full Privacy** - All data stays on your machine  
‚úÖ **Offline Capable** - Works without internet  
‚úÖ **Open Source Models** - llama3.1, mistral, phi3, etc.  

---

## üöÄ Quick Start Options

### Option 1: Ollama Agent (FREE, 5 minutes)

**Best for:** Development, privacy-sensitive data, cost savings

```bash
# 1. Install Ollama
brew install ollama  # macOS
# or: curl -fsSL https://ollama.ai/install.sh | sh  # Linux

# 2. Start service and pull model
ollama serve &
ollama pull llama3.1:8b

# 3. Run the agent
npm run agent:ollama
```

**See:** [OLLAMA_QUICK_START.md](docs/OLLAMA_QUICK_START.md) for details

---

### Option 2: Claude Agent (Premium, 2 minutes)

**Best for:** Production, best quality, fastest setup

#### Step 1: Get API Key

1. Go to https://console.anthropic.com/
2. Sign up or log in
3. Click "API Keys" ‚Üí "Create Key"
4. Copy your key (starts with `sk-ant-api03-...`)

#### Step 2: Configure

Add to your `.env` file:

```bash
ANTHROPIC_API_KEY=sk-ant-api03-your-key-here
```

Or export in terminal:

```bash
export ANTHROPIC_API_KEY=sk-ant-api03-your-key-here
```

#### Step 3: Run!

```bash
npm run agent
```

You'll see:

```
ü§ñ AI Agent CLI

Initializing MCP server...
‚úÖ Agent ready!

Type your question or command:
You: _
```

---

### Option 3: Use Both! üéØ

**Recommended approach:**
- Use **Ollama** for development and testing (free)
- Use **Claude** for production and important queries (quality)

```bash
# Terminal 1: Ollama for dev
npm run agent:ollama

# Terminal 2: Claude for production
npm run agent
```

---

## üí° Try These Queries (Works with Both)

### Simple
```
"What are the active sprints?"
"Show me sprint 123"
"List blocked issues"
```

### Medium
```
"What's the completion rate for sprint 123?"
"Show me all high-priority bugs"
"Find commits from last week with Jira references"
```

### Complex
```
"Analyze sprint 123: show completion rate, list blockers, and compare with sprint 122. Then suggest improvements."

"Find all high-priority bugs in active sprints, check if they have GitHub PRs, and generate a summary report."
```

## üîß CLI Commands (Both Agents)

While in the CLI:

- `tools` - List all 14 available MCP tools
- `models` - List available models (Ollama only)
- `history` - Show conversation history
- `clear` - Clear conversation
- `exit` or `quit` - Exit CLI

## üìä Example Session

```
You: What are the active sprints in project SCRUM?

Agent: I found 3 active sprints in project SCRUM:

1. **Sprint 45: Development Phase**
   - 20 issues total  
   - 13 completed (65%)
   - 7 in progress

2. **Sprint 46: Testing Phase**
   - 15 issues total
   - 6 completed (40%)
   - 9 in progress

3. **Sprint 47: Planning Phase**
   - 8 issues total
   - 1 completed (13%)
   - 7 in progress

[Tools: jira_get_sprints, jira_get_sprint_issues | Iterations: 2 | Time: 3.2s]

You: Show me blocked issues in the first one

Agent: Here are the blocked issues in Sprint 45:

1. **SCRUM-234**: Cannot deploy to staging
   - Priority: High
   - Blocker: Waiting for infrastructure team

2. **SCRUM-245**: API integration failing
   - Priority: Medium
   - Blocker: Third-party service outage

[Tools: jira_get_sprint_issues | Iterations: 1 | Time: 1.5s]

You: exit

üëã Goodbye!
```

## üåê Next Steps

### 1. Try Both CLIs

```bash
# Claude agent (premium)
npm run agent

# Ollama agent (free)
npm run agent:ollama
```

### 2. Add to Your Web Server

In `src/web-server.ts`:

```typescript
import { createAgentRouter } from '@/agent/agent-api';
import { createOllamaAgentRouter } from '@/agent/ollama-agent-api';

// After MCP server initialization
// Claude agent
const agentRouter = createAgentRouter(toolRegistry, context);
app.use('/api/agent', agentRouter);

// Ollama agent  
const ollamaRouter = createOllamaAgentRouter(toolRegistry, context);
app.use('/api/agent/ollama', ollamaRouter);

console.log('‚úÖ AI Agent API at /api/agent (Claude)');
console.log('‚úÖ Ollama Agent API at /api/agent/ollama (FREE)');
```

Then test the APIs:

```bash
# Claude
curl -X POST http://localhost:3002/api/agent/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "What are the active sprints?"}'

# Ollama
curl -X POST http://localhost:3002/api/agent/ollama/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "What are the active sprints?"}'
```

### 3. Build a Chat UI

See `docs/AI_AGENT_SETUP.md` and `docs/OLLAMA_AGENT_SETUP.md` for complete React examples!

## üìö Documentation

### Claude Agent
- **Setup Guide**: `docs/AI_AGENT_SETUP.md`
- **Quick Reference**: `docs/AI_AGENT_QUICK_REF.md`
- **Full Documentation**: `src/agent/README.md`
- **Code Examples**: `src/agent/example-usage.ts` (run: `npm run agent:example`)

### Ollama Agent
- **Quick Start (5 min)**: `docs/OLLAMA_QUICK_START.md` ‚≠ê
- **Setup Guide**: `docs/OLLAMA_AGENT_SETUP.md`

### Comparison
- **Claude vs Ollama**: `docs/AGENT_COMPARISON.md` üéØ

## üí∞ Cost Comparison

### Claude Agent

Using Claude Sonnet (default):

| Query Type | Tools Used | Typical Cost |
|------------|------------|--------------|
| Simple | 1-2 | $0.01-0.02 |
| Medium | 2-4 | $0.02-0.05 |
| Complex | 5+ | $0.05-0.10 |
| Full Report | 5-10 | $0.10-0.25 |

**Example:** 100 queries/day = ~$2-5/day = ~$60-150/month

### Ollama Agent

| Query Type | Tools Used | Cost |
|------------|------------|------|
| Any | Any | **$0.00 (FREE!)** |

**But consider:**
- Hardware: One-time $500-2000 (if you need a GPU)
- Electricity: ~$5-20/month
- **Break-even:** ~100-500 queries/month

**Recommendation:** Use Ollama for dev (free), Claude for production (quality)

**Want even cheaper?** Switch to Haiku model (10x cheaper):
```bash
export AGENT_MODEL=claude-3-haiku-20240307
```

**Or go FREE:** Use Ollama agent (`npm run agent:ollama`)

## üõ†Ô∏è Available Tools (14)

Your agent has access to:

### Jira Tools (5)
- Get sprints
- Get sprint issues
- Get sprint details
- Get issue details
- Search issues with JQL

### GitHub Tools (5)
- Get commits
- Get pull requests
- Search commits by message
- Search PRs by date
- Find commits with Jira references

### Reporting Tools (2)
- Generate sprint report
- Get sprint metrics

### Utility Tools (2)
- Health check
- Cache statistics

## üéØ Use Cases

### Sprint Management
- "What's our current sprint status?"
- "Show me blocked issues"
- "Generate a sprint report"

### Team Analytics
- "Who are the top contributors this month?"
- "What's our velocity trend?"
- "Compare last two sprints"

### Integration Analysis
- "Find commits without Jira references"
- "Show PRs merged last week"
- "Match commits to sprint issues"

### Planning
- "Analyze sprint capacity"
- "Identify bottlenecks"
- "Suggest improvements"

## üêõ Troubleshooting

### Claude Agent Issues

**"Error: ANTHROPIC_API_KEY not found"**
```bash
export ANTHROPIC_API_KEY=sk-ant-api03-...
```

**"Response is slow"**
- Use streaming API: `npm run agent`
- Switch to Haiku: `export AGENT_MODEL=claude-3-haiku-20240307`
- Reduce max tokens: `export AGENT_MAX_TOKENS=2048`

**"Costs are high"**
- Use Haiku instead of Sonnet
- Reduce max iterations: `export AGENT_MAX_ITERATIONS=5`
- **Or switch to Ollama (FREE):** `npm run agent:ollama`

### Ollama Agent Issues

**"Ollama is not running"**
```bash
ollama serve &
```

**"Model not found"**
```bash
ollama pull llama3.1:8b
```

**"Out of memory"**
```bash
# Use smaller model
ollama pull phi3:mini
export OLLAMA_MODEL=phi3:mini
```

**"Too slow"**
- Get a GPU (5-10x faster)
- Use smaller model: `phi3:mini`
- Close other apps to free RAM

### General Issues

**"Tool execution failed"**
- Make sure your Jira/GitHub credentials are configured
- Check that the MCP server is running
- Verify tool parameters

See detailed troubleshooting:
- Claude: `docs/AI_AGENT_SETUP.md`
- Ollama: `docs/OLLAMA_AGENT_SETUP.md`

## üîó Resources

### Claude Agent
- **Anthropic Console**: https://console.anthropic.com/
- **API Documentation**: https://docs.anthropic.com/
- **Tool Use Guide**: https://docs.anthropic.com/en/docs/build-with-claude/tool-use

### Ollama Agent
- **Ollama Website**: https://ollama.ai/
- **Model Library**: https://ollama.ai/library
- **Discord**: https://discord.gg/ollama

### General
- **MCP Protocol**: https://modelcontextprotocol.io/

## üéâ You're Ready!

Choose your path:

### ü¶ô Start with FREE Ollama (Recommended for dev)
```bash
# 5-minute setup
brew install ollama
ollama serve &
ollama pull llama3.1:8b
npm run agent:ollama
```

### ü§ñ Or use Premium Claude (Recommended for production)
```bash
# 2-minute setup
export ANTHROPIC_API_KEY=sk-ant-...
npm run agent
```

### üéØ Or use BOTH! (Best of both worlds)
```bash
# Terminal 1: Free local dev
npm run agent:ollama

# Terminal 2: Premium quality  
npm run agent
```

**Happy querying! üöÄ‚ú®**

Start the CLI and ask your first question:

```bash
npm run agent
```

Then type:
```
What are the active sprints?
```

---

**Questions?** Check the documentation in `docs/AI_AGENT_SETUP.md`

**Need help?** See troubleshooting section above

**Want more?** Explore `src/agent/example-usage.ts` for advanced usage

Enjoy your new AI agent! üöÄ
